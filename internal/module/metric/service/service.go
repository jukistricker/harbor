package service

import (
	"database/sql"
	"encoding/json"
	"fmt"
	"harbor/internal/module/metric/model"
	"log"
	"path/filepath"
	"sync"
)

type Processor struct {
	db         *sql.DB
	lastStates map[uint32]model.AgentPayload
	buffer     []model.CalculatedMetric
	mu         sync.Mutex
}

func NewProcessor(db *sql.DB) *Processor {
	return &Processor{
		db:         db,
		lastStates: make(map[uint32]model.AgentPayload),
		buffer:     make([]model.CalculatedMetric, 0, 100),
	}
}

func (p *Processor) Process(current model.AgentPayload) {
	p.mu.Lock()
	defer p.mu.Unlock()

	prev, exists := p.lastStates[current.Metadata.TargetPID]
	p.lastStates[current.Metadata.TargetPID] = current

	if !exists {
		return 
	}

	deltaTime := float64(current.Metadata.Timestamp - prev.Metadata.Timestamp)
	deltaCycles := float64(current.Layer2.TotalCycles - prev.Layer2.TotalCycles)
	
	cpuPercent := 0.0
	if deltaTime > 0 {
		// Windows FileTime unit (100ns) -> 1s = 10^7 units
		cpuPercent = (deltaCycles / (deltaTime * 10000000.0)) * 100.0
	}

	memGrowth := int64(current.Layer2.MemPrivate) - int64(prev.Layer2.MemPrivate)

	calc := model.CalculatedMetric{
		TargetID:          fmt.Sprintf("%s_%d", filepath.Base(current.Metadata.ProcessPath), current.Metadata.TargetPID),
		Timestamp:         current.Metadata.Timestamp,
		CPUUsagePercent:   cpuPercent,
		MemPrivateBytes:   current.Layer2.MemPrivate,
		MemGrowthBytes:    memGrowth,
		HandleCount:       current.Layer2.HandleCount,
		ThreadCount:       current.Layer2.ThreadCount,
		ActiveConnections: current.Layer3.ActiveConns,
		NetOutErrors:      current.Layer4.NetOutErrors,
		Mode:              current.Mode,
	}
	p.buffer = append(p.buffer, calc)

	if len(p.buffer) >= 50 {
		p.Flush()
	}
}

func (p *Processor) ProcessRawMetric(agentID string, rawData []byte) {
    var payload model.AgentPayload
    if err := json.Unmarshal(rawData, &payload); err != nil {
        log.Printf("‚ö†Ô∏è [Metric] Failed to unmarshal from %s: %v", agentID, err)
        return
    }

    // G√°n AgentID v√†o Metadata n·∫øu b·∫°n mu·ªën ph√¢n bi·ªát c√°c m√°y
    payload.Metadata.AgentID = agentID 

    // G·ªçi h√†m Process ƒë·ªÉ t√≠nh to√°n Delta v√† Buffer
    p.Process(payload)
}

func (p *Processor) Flush() {
	p.mu.Lock()
    count := len(p.buffer) // L·∫•y s·ªë l∆∞·ª£ng tr∆∞·ªõc khi clear
    if count == 0 {
        p.mu.Unlock()
        return
    }
    p.mu.Unlock()

	// B·∫Øt ƒë·∫ßu Transaction ƒë·ªÉ t·ªëi ∆∞u Batch Insert cho SQLite
	tx, err := p.db.Begin()
	if err != nil {
		log.Printf("[DB] Failed to begin transaction: %v", err)
		return
	}

	stmt, err := tx.Prepare(`
		INSERT INTO harbor_metrics (
			target_id, timestamp, handle_count, thread_count, 
			mem_private, total_cycles, active_connections, 
			disk_read, disk_write, net_out_errors, mode
		) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
	`)
	if err != nil {
		log.Printf("[DB] Failed to prepare statement: %v", err)
		tx.Rollback()
		return
	}
	defer stmt.Close()

	for _, m := range p.buffer {
		// L∆∞u √Ω: L∆∞u total_cycles th·ª±c t·∫ø (Raw) 
		// N·∫øu mu·ªën l∆∞u CPU %, s·ª≠a schema init.sql th√™m c·ªôt
		_, err := stmt.Exec(
			m.TargetID, m.Timestamp, m.HandleCount, m.ThreadCount,
			m.MemPrivateBytes, uint64(m.CPUUsagePercent*100), // Trick: L∆∞u CPU*100 v√†o total_cycles n·∫øu ch∆∞a k·ªãp s·ª≠a schema
			m.ActiveConnections, 0, 0, m.NetOutErrors, m.Mode,
		)
		if err != nil {
			log.Printf("[DB] Insert error: %v", err)
		}
	}

	if err := tx.Commit(); err != nil {
		log.Printf("[DB] Transaction commit error: %v", err)
	}

	// Clear buffer nh∆∞ng gi·ªØ capacity
	p.mu.Lock()
    p.buffer = p.buffer[:0]
    p.mu.Unlock()
    log.Printf("üíæ [Processor] Flushed %d metrics to DB", count)
}